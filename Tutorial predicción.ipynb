{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tutorial utiliza modelos LSTM para predecir el nivel de emergencia de la estación Quintero (k540) en los intervalos 0-8, 8-16 y 16-24 horas siguientes. Para poder ejecutar este tutorial necesitas cumplir las siguientes condiciones:\n",
    "\n",
    "* Modelos: se requiere tener los modelos ya entrenados para cada escenario. Para entrenar tus propios modelos, debes ejecutar `run_experiment.sh` con las configuraciones que más te interesen. De todas formas, en la carpeta *models* se brinda los modelos listos para ser utilizados.\n",
    "\n",
    "\n",
    "* Testing set: se requiere el testing set para realizar las evaluaciones del modelo. Al igual que en la condición anterior, para generar tus propios testing set con nuevos datos, debes ejecutar `generator_inference_file.sh`.\n",
    "\n",
    "Para continuar con el tutorial, los niveles de emergencia se categorizarán en 3 niveles dependiendo de las mediciones asociadas a la concentración del SO2, mas información respecto a la problemática y como se llevo a cabo el análisis recomendamos leer nuestro trabajo de investigación.\n",
    "\n",
    "Antes de ejecutar el código, recomendamos generar el ambiente virtual con el archivo `environment_tf_keras.yml`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paquetes y funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los distintos paquetes a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "\n",
    "from src.nowcastlib.dnn_models_f1 import build_categorical_model\n",
    "from src.nowcastlib.data_handlers import MaxCategorical\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `configure_model()` es la encargada de reconstruir el modelo a través de los distintos archivos de configuración, referentes al conjunto de datos (*ds_config*), entrenamiento (*tr_config*) y modelo (*md_config*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_model(ds_config, tr_config, md_config):\n",
    "\n",
    "    ds_config = tr_config['dataset']\n",
    "    training_fields = ds_config['training_fields']\n",
    "    n_variables = len(training_fields)\n",
    "    \n",
    "    number_class = int(md_config['n_class'])\n",
    "    if number_class == 2:\n",
    "        ranges = md_config['normalized_ranges_2class']\n",
    "    elif number_class == 3:\n",
    "        ranges = md_config['normalized_ranges_3class']\n",
    "    elif number_class == 4:\n",
    "        ranges = md_config['normalized_ranges_4class']\n",
    "    else:\n",
    "        raise ValueError(\"number of classes is not supported\")\n",
    "\n",
    "    lag = int(md_config['lag'])\n",
    "    boost = int(md_config['boost'])\n",
    "    lstm_neurons = int(md_config['lstm_neurons'])\n",
    "    fcn_neurons = int(md_config['fcn_neurons'])\n",
    "    fcn_layers = int(md_config['fcn_layers'])\n",
    "    fcn_dropout = float(md_config['dropout'])\n",
    "    \n",
    "    train_config = tr_config['training']\n",
    "    n_epochs = int(train_config['number_of_epochs'])\n",
    "    batch_size = int(train_config['batch_size'])\n",
    "    learning_rate = float(train_config['learning_rate'])\n",
    "    beta_1 = float(train_config['beta_1'])\n",
    "    beta_2 = float(train_config['beta_2'])\n",
    "\n",
    "    # define model \n",
    "    compiled_model = build_categorical_model(lag, n_variables, number_class, lstm_neurons, fcn_neurons, fcn_layers, \n",
    "    fcn_dropout, learning_rate, beta_1, beta_2)\n",
    "    \n",
    "    compiled_model.summary()\n",
    "    return compiled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecturas archivos de configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como especificaba la función anterior, necesitamos los distintos archivos de configuración para reconstruir el modelo, por lo que definimos la ruta de estos archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_conf_path = 'config/sma_uai_alldata.json'\n",
    "tr_conf_path = 'config/training_config.json'\n",
    "md_conf_path = 'config/model_config.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, creamos una configuración maestra que contemple todos los archivos de configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_config = dict()\n",
    "for path in [ds_conf_path, tr_conf_path, md_conf_path]:\n",
    "    config_file = open(path, 'r')\n",
    "    config = json.loads(config_file.read())\n",
    "    config_file.close()\n",
    "    master_config.update(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras esto, desde la configuración maestra guardamos las configuraciones asociadas a los datos, entrenamiento y modelo sobre distintos objetos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_conf = master_config[\"dataset\"]\n",
    "tr_conf = master_config[\"training\"]\n",
    "md_conf = master_config[\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones sobre ventana de tiempo 0-8 horas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especificamos la estación a predecir, además del número de clases a considerar y la ventana de predicción. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estacion = 'k540'\n",
    "n_class = 3\n",
    "boost = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazamos los valores definidos anteriormente en las configuraciones del modelo y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_conf['boost'] = str(boost)\n",
    "md_conf['n_class'] = str(n_class) \n",
    "tr_conf['dataset']['target_field'] = str(estacion) + '_so2_ppb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargamos el testing set, presentes en la carpeta *inference_files*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = '_inference_c' + str(n_class) + '_h' + str(boost) + '.pkl'\n",
    "\n",
    "with open('inference_files/testx' + outfile, 'rb') as handle:\n",
    "    test_x = pickle.load(handle)\n",
    "with open('inference_files/testy' + outfile, 'rb') as handle:\n",
    "    test_y = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si observamos las dimensiones del testing set, se tiene 6415 muestras. Para el caso de test_x, cada muestra posee 18 horas de información considerando 185 variables, mientras que test_y posee el nivel de emergencia asociada a cada muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6415, 18, 185) (6415, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruimos el modelo con la función `configure_model()`, además de añadir los pesos del modelo ya entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 18, 185)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 18, 128)           160768    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "rng_pred (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 786,691\n",
      "Trainable params: 786,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ncast_model = configure_model(ds_conf, tr_conf, md_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_filename = 'models/model_' + str(estacion) + '_' + str(n_class) + 'class_' + str(boost) + 'boost.h5'\n",
    "ncast_model.load_weights(weights_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos las predicciones sobre el test_x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = ncast_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos las dimensiones, tanto para las predicciones como los valores reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6415, 3) (6415, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pred_test.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a evaluar el rendimiento del modelo sobre el test_y. En primer lugar, creamos la respectiva matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bueno</th>\n",
       "      <th>regular</th>\n",
       "      <th>grave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bueno</th>\n",
       "      <td>5816</td>\n",
       "      <td>112</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grave</th>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bueno  regular  grave\n",
       "bueno     5816      112    299\n",
       "regular     80       15     31\n",
       "grave       31       10     21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['bueno', 'regular', 'grave']\n",
    "pd.DataFrame(confusion_matrix(np.argmax(test_y, axis=1), np.argmax(pred_test, axis=1), labels = [0,1,2]), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, generemos el reporte de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      6227\n",
      "           1       0.11      0.12      0.11       126\n",
      "           2       0.06      0.34      0.10        62\n",
      "\n",
      "    accuracy                           0.91      6415\n",
      "   macro avg       0.38      0.46      0.39      6415\n",
      "weighted avg       0.96      0.91      0.93      6415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_y.argmax(axis=1), pred_test.argmax(axis=1))\n",
    "str_rep = \"{}\".format(report)\n",
    "print(str_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones sobre ventana de tiempo 8-16 horas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anteriormente, realizamos predicciones para las primeras 8 horas. Entonces replicaremos el proceso anterior pero considerando la siguiente ventana de predicción, es decir, las 8-16 horas siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estacion = 'k540'\n",
    "n_class = 3\n",
    "boost = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el testing set para este nueva ventana de predicción, además de reconstruir el modelo con sus respectivos pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 18, 185)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 18, 128)           160768    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "rng_pred (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 786,691\n",
      "Trainable params: 786,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "outfile = '_inference_c' + str(n_class) + '_h' + str(boost) + '.pkl'\n",
    "\n",
    "with open('inference_files/testx' + outfile, 'rb') as handle:\n",
    "    test_x = pickle.load(handle)\n",
    "with open('inference_files/testy' + outfile, 'rb') as handle:\n",
    "    test_y = pickle.load(handle)\n",
    "\n",
    "ncast_model = configure_model(ds_conf, tr_conf, md_conf)\n",
    "\n",
    "weights_filename = 'models/model_' + str(estacion) + '_' + str(n_class) + 'class_' + str(boost) + 'boost.h5'\n",
    "ncast_model.load_weights(weights_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos las predicciones sobre el test_x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = ncast_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el rendimiento observando su matriz de confusión y generando el reporte de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bueno</th>\n",
       "      <th>regular</th>\n",
       "      <th>grave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bueno</th>\n",
       "      <td>5971</td>\n",
       "      <td>92</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <td>97</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grave</th>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bueno  regular  grave\n",
       "bueno     5971       92    103\n",
       "regular     97        8     21\n",
       "grave       38        7     21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['bueno', 'regular', 'grave']\n",
    "pd.DataFrame(confusion_matrix(np.argmax(test_y, axis=1), np.argmax(pred_test, axis=1), labels = [0,1,2]), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      6166\n",
      "           1       0.07      0.06      0.07       126\n",
      "           2       0.14      0.32      0.20        66\n",
      "\n",
      "    accuracy                           0.94      6358\n",
      "   macro avg       0.40      0.45      0.41      6358\n",
      "weighted avg       0.95      0.94      0.95      6358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_y.argmax(axis=1), pred_test.argmax(axis=1))\n",
    "str_rep = \"{}\".format(report)\n",
    "print(str_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones sobre ventana de tiempo 16-24 horas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, realizamos predicciones sobre la ventana restante de 16-24 horas, así abarcamos el comportamiento de los niveles de emergencia por día siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "estacion = 'k540'\n",
    "n_class = 3\n",
    "boost = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el respectivo testing set, además de reconstruir el modelo con sus pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 18, 185)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 18, 128)           160768    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "rng_pred (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 786,691\n",
      "Trainable params: 786,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "outfile = '_inference_c' + str(n_class) + '_h' + str(boost) + '.pkl'\n",
    "\n",
    "with open('inference_files/testx' + outfile, 'rb') as handle:\n",
    "    test_x = pickle.load(handle)\n",
    "with open('inference_files/testy' + outfile, 'rb') as handle:\n",
    "    test_y = pickle.load(handle)\n",
    "\n",
    "ncast_model = configure_model(ds_conf, tr_conf, md_conf)\n",
    "\n",
    "weights_filename = 'models/model_' + str(estacion) + '_' + str(n_class) + 'class_' + str(boost) + 'boost.h5'\n",
    "ncast_model.load_weights(weights_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos las predicciones sobre el test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = ncast_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el rendimiento observando su matriz de confusión y generando el reporte de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bueno</th>\n",
       "      <th>regular</th>\n",
       "      <th>grave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bueno</th>\n",
       "      <td>5770</td>\n",
       "      <td>169</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <td>90</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grave</th>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bueno  regular  grave\n",
       "bueno     5770      169    163\n",
       "regular     90       27      9\n",
       "grave       31       15     20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['bueno', 'regular', 'grave']\n",
    "pd.DataFrame(confusion_matrix(np.argmax(test_y, axis=1), np.argmax(pred_test, axis=1), labels = [0,1,2]), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      6102\n",
      "           1       0.13      0.21      0.16       126\n",
      "           2       0.10      0.30      0.16        66\n",
      "\n",
      "    accuracy                           0.92      6294\n",
      "   macro avg       0.40      0.49      0.43      6294\n",
      "weighted avg       0.95      0.92      0.94      6294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_y.argmax(axis=1), pred_test.argmax(axis=1))\n",
    "str_rep = \"{}\".format(report)\n",
    "print(str_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
